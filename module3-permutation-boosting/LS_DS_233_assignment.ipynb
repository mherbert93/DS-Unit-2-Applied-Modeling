{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "LS_DS_233_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mherbert93/DS-Unit-2-Applied-Modeling/blob/master/module3-permutation-boosting/LS_DS_233_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxwxFfX17-f3",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 3*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Permutation & Boosting\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint.\n",
        "\n",
        "## Assignment\n",
        "\n",
        "Complete these tasks for your project, and document your work.\n",
        "\n",
        "- [x] If you haven't completed assignment #1, please do so first.\n",
        "- [x] Continue to clean and explore your data. Make exploratory visualizations.\n",
        "- [x] Fit a model. Does it beat your baseline? \n",
        "- [x] Try xgboost.\n",
        "- [x] Get your model's permutation importances.\n",
        "\n",
        "You should try to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
        "\n",
        "But, if you aren't ready to try xgboost and permutation importances with your dataset today, that's okay. You can practice with another dataset instead. You may choose any dataset you've worked with previously.\n",
        "\n",
        "The data subdirectory includes the Titanic dataset for classification and the NYC apartments dataset for regression. You may want to choose one of these datasets, because example solutions will be available for each.\n",
        "\n",
        "\n",
        "## Reading\n",
        "\n",
        "Top recommendations in _**bold italic:**_\n",
        "\n",
        "#### Permutation Importances\n",
        "- _**[Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)**_\n",
        "- [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "\n",
        "#### (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        "#### Gradient Boosting\n",
        "  - [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n",
        "  - [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf), Chapter 8\n",
        "  - _**[Gradient Boosting Explained](https://www.gormanalysis.com/blog/gradient-boosting-explained/)**_ — Ben Gorman\n",
        "  - [Gradient Boosting Explained](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html) — Alex Rogozhnikov\n",
        "  - [How to explain gradient boosting](https://explained.ai/gradient-boosting/) — Terence Parr & Jeremy Howard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Q9Q6Xm7RQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00397/LasVegasTripAdvisorReviews-Dataset.csv\", sep=';')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aSpHb00s7RQT",
        "colab_type": "code",
        "colab": {},
        "outputId": "8d1bb21f-3f8e-4591-f701-11c3254f7aaa"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  User country  Nr. reviews  Nr. hotel reviews  Helpful votes  Score  \\\n",
              "0          USA           11                  4             13      5   \n",
              "1          USA          119                 21             75      3   \n",
              "2          USA           36                  9             25      5   \n",
              "3           UK           14                  7             14      4   \n",
              "4       Canada            5                  5              2      4   \n",
              "\n",
              "  Period of stay Traveler type Pool  Gym Tennis court Spa Casino  \\\n",
              "0        Dec-Feb       Friends   NO  YES           NO  NO    YES   \n",
              "1        Dec-Feb      Business   NO  YES           NO  NO    YES   \n",
              "2        Mar-May      Families   NO  YES           NO  NO    YES   \n",
              "3        Mar-May       Friends   NO  YES           NO  NO    YES   \n",
              "4        Mar-May          Solo   NO  YES           NO  NO    YES   \n",
              "\n",
              "  Free internet                              Hotel name Hotel stars  \\\n",
              "0           YES  Circus Circus Hotel & Casino Las Vegas           3   \n",
              "1           YES  Circus Circus Hotel & Casino Las Vegas           3   \n",
              "2           YES  Circus Circus Hotel & Casino Las Vegas           3   \n",
              "3           YES  Circus Circus Hotel & Casino Las Vegas           3   \n",
              "4           YES  Circus Circus Hotel & Casino Las Vegas           3   \n",
              "\n",
              "   Nr. rooms User continent  Member years Review month Review weekday  \n",
              "0       3773  North America             9      January       Thursday  \n",
              "1       3773  North America             3      January         Friday  \n",
              "2       3773  North America             2     February       Saturday  \n",
              "3       3773         Europe             6     February         Friday  \n",
              "4       3773  North America             7        March        Tuesday  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User country</th>\n",
              "      <th>Nr. reviews</th>\n",
              "      <th>Nr. hotel reviews</th>\n",
              "      <th>Helpful votes</th>\n",
              "      <th>Score</th>\n",
              "      <th>Period of stay</th>\n",
              "      <th>Traveler type</th>\n",
              "      <th>Pool</th>\n",
              "      <th>Gym</th>\n",
              "      <th>Tennis court</th>\n",
              "      <th>Spa</th>\n",
              "      <th>Casino</th>\n",
              "      <th>Free internet</th>\n",
              "      <th>Hotel name</th>\n",
              "      <th>Hotel stars</th>\n",
              "      <th>Nr. rooms</th>\n",
              "      <th>User continent</th>\n",
              "      <th>Member years</th>\n",
              "      <th>Review month</th>\n",
              "      <th>Review weekday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>USA</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>Dec-Feb</td>\n",
              "      <td>Friends</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>YES</td>\n",
              "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
              "      <td>3</td>\n",
              "      <td>3773</td>\n",
              "      <td>North America</td>\n",
              "      <td>9</td>\n",
              "      <td>January</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>USA</td>\n",
              "      <td>119</td>\n",
              "      <td>21</td>\n",
              "      <td>75</td>\n",
              "      <td>3</td>\n",
              "      <td>Dec-Feb</td>\n",
              "      <td>Business</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>YES</td>\n",
              "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
              "      <td>3</td>\n",
              "      <td>3773</td>\n",
              "      <td>North America</td>\n",
              "      <td>3</td>\n",
              "      <td>January</td>\n",
              "      <td>Friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>USA</td>\n",
              "      <td>36</td>\n",
              "      <td>9</td>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>Mar-May</td>\n",
              "      <td>Families</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>YES</td>\n",
              "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
              "      <td>3</td>\n",
              "      <td>3773</td>\n",
              "      <td>North America</td>\n",
              "      <td>2</td>\n",
              "      <td>February</td>\n",
              "      <td>Saturday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UK</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>Mar-May</td>\n",
              "      <td>Friends</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>YES</td>\n",
              "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
              "      <td>3</td>\n",
              "      <td>3773</td>\n",
              "      <td>Europe</td>\n",
              "      <td>6</td>\n",
              "      <td>February</td>\n",
              "      <td>Friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Canada</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>Mar-May</td>\n",
              "      <td>Solo</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>YES</td>\n",
              "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
              "      <td>3</td>\n",
              "      <td>3773</td>\n",
              "      <td>North America</td>\n",
              "      <td>7</td>\n",
              "      <td>March</td>\n",
              "      <td>Tuesday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 522
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fpWK0Yc17RQZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "9c82ee3c-351d-4c3f-e995-4c2f0db08ae0"
      },
      "source": [
        "df['Score'].value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    0.450397\n",
              "4    0.325397\n",
              "3    0.142857\n",
              "2    0.059524\n",
              "1    0.021825\n",
              "Name: Score, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 523
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "L1dbZeFd7RQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, train_size=0.80, test_size=0.20, stratify=df['Score'], random_state=1337)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "onRAPLiW7RQg",
        "colab_type": "code",
        "colab": {},
        "outputId": "a5023b12-cb5b-448f-b4bb-a4e9643f87e4"
      },
      "source": [
        "train['Score'].value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    0.449132\n",
              "4    0.325062\n",
              "3    0.143921\n",
              "2    0.059553\n",
              "1    0.022333\n",
              "Name: Score, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 525
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lqlN3Ku77RQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrangle(X):\n",
        "\n",
        "    X = X.copy()\n",
        "\n",
        "    def country_aggregation(row): #reduce number of country categories to 4. 'USA', 'Canada', 'UK', and all else 'other'.\n",
        "        if row['User country'] != \"USA\" and row['User country'] != 'Canada' and row['User country'] != 'UK':\n",
        "            return \"Other\"\n",
        "        else:\n",
        "            return row['User country']\n",
        "\n",
        "    def score_aggregation(row):\n",
        "        if row['Score'] == 5:\n",
        "            return \"Excellent\"\n",
        "        elif row['Score'] == 4 or row['Score'] == 3:\n",
        "            return \"Average\"\n",
        "        else:\n",
        "            return \"Bad\"\n",
        "\n",
        "    X['User country'] = X.apply(country_aggregation, axis=1)\n",
        "    X['Score'] = X.apply(score_aggregation, axis=1)\n",
        "\n",
        "    X = X.drop(['Member years'], axis=1)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "U1X_gvCa7RQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = wrangle(train)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MmzOA99g7RQs",
        "colab_type": "code",
        "colab": {},
        "outputId": "7a73201c-d1f0-466c-856d-c847e615df1e"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "majority_class = train['Score'].mode()[0]\n",
        "y_pred = [majority_class] * len(train['Score'])\n",
        "\n",
        "print(\"Train baseline accuracy is: \", accuracy_score(train['Score'], y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train baseline accuracy is:  0.46898263027295284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "SSUP3kx_7RQv",
        "colab_type": "code",
        "colab": {},
        "outputId": "b39d6d7e-78d1-460a-cadd-c4ebb1688eaa"
      },
      "source": [
        "majority_class = test['Score'].mode()[0]\n",
        "y_pred = [majority_class] * len(test['Score'])\n",
        "\n",
        "print(\"Test baseline accuracy is: \", accuracy_score(test['Score'], y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test baseline accuracy is:  0.46534653465346537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0S1HZSJY7RQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = 'Score'\n",
        "\n",
        "train_features = train.drop([target], axis=1)\n",
        "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "categorical_features = train_features.select_dtypes(exclude='number').nunique().index.tolist()\n",
        "\n",
        "\n",
        "features = numeric_features + categorical_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ltJ7zvMl7RQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = train[target]\n",
        "X_train = train[features]\n",
        "X_test = test[features]\n",
        "y_test = test[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AvAoZuHn7RQ5",
        "colab_type": "code",
        "colab": {},
        "outputId": "6ce40a49-5502-4fe1-8eb3-37bff5abbffc"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(403, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 532
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "g4Fcatd_7RQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import category_encoders as ce\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "#When hyperparamater tuning, set tune to \"True\", and mark each model that we want to tune to \"True\".\n",
        "tune = False\n",
        "forest = True\n",
        "logistic = True\n",
        "xgboost = True\n",
        "\n",
        "forest_distributions = {\n",
        "    'model__n_estimators': range(250, 500, 50),\n",
        "    'model__max_depth': range(3, 14),\n",
        "    'model__max_features': range(2, 14),\n",
        "    'model__min_samples_leaf': range(2, 4)\n",
        "}\n",
        "logistic_distributions = {\n",
        "    'kbest__k': range(1, 20),\n",
        "    'model__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "}\n",
        "\n",
        "xgboost_distributions = {\n",
        "    'model__n_estimators': [75, 100, 125, 150, 175],\n",
        "    'model__max_depth': [6, 7, 8, 9, 10, 11, 12, 13],\n",
        "    'model__learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.07, 0.10, 0.12, 0.14, 0.16],\n",
        "    'model__min_child_leaf':[1, 2, 3],\n",
        "    'model__min_child_weight': [1, 2, 3, 4],\n",
        "    'model__colsample_bytree':[0.2, 0.3, 0.4, 0.50, 0.60, 0.70],\n",
        "    'model__subsample':[0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    'model__gamma':[0],\n",
        "    'model__scale_pos_weight': [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70,\n",
        "                                75, 80, 85, 90, 95, 100]\n",
        " }\n",
        "\n",
        "if tune: #If we are hyperparamater tuning, pass no parameters into estimators and find paramaters via GridSearchCV / RandomizedSearchCV\n",
        "\n",
        "    forest_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
        "                           ('model', RandomForestClassifier(random_state=1337))])\n",
        "\n",
        "    logistic_pipeline = Pipeline([('encoder', ce.OneHotEncoder()),\n",
        "                                ('scaler', StandardScaler()),\n",
        "                                ('kbest', SelectKBest()),\n",
        "                                ('model', LogisticRegression(random_state=1337))])\n",
        "\n",
        "    xgboost_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
        "                           ('model', XGBClassifier(seed=1337))])\n",
        "\n",
        "    forest_search = GridSearchCV(\n",
        "        forest_pipeline,\n",
        "        param_grid=forest_distributions,\n",
        "        cv=3,\n",
        "        scoring='neg_log_loss',\n",
        "        verbose=10,\n",
        "        n_jobs=15\n",
        "    )\n",
        "    logistic_search = GridSearchCV(\n",
        "        logistic_pipeline,\n",
        "        param_grid=logistic_distributions,\n",
        "        cv=3,\n",
        "        scoring='neg_log_loss',\n",
        "        verbose=10,\n",
        "        n_jobs=15\n",
        "    )\n",
        "    xgboost_search = RandomizedSearchCV(\n",
        "        estimator=xgboost_pipeline,\n",
        "        param_distributions=xgboost_distributions,\n",
        "        n_iter=10000,\n",
        "        cv=3,\n",
        "        scoring='neg_log_loss',\n",
        "        verbose=10,\n",
        "        random_state=1337,\n",
        "        n_jobs=15\n",
        "    )\n",
        "\n",
        "    X_train, y_train = RandomOverSampler(sampling_strategy='not majority').fit_resample(X_train, y_train)\n",
        "\n",
        "    if forest:\n",
        "        forest_search.fit(X_train, y_train)\n",
        "        forest_train_pred = forest_search.predict(X_train)\n",
        "        forest_test_pred = forest_search.predict(X_test)\n",
        "        forest_test_pred_proba = forest_search.predict_proba(X_test)\n",
        "\n",
        "    if logistic:\n",
        "        logistic_search.fit(X_train, y_train)\n",
        "        logistic_train_pred = logistic_search.predict(X_train)\n",
        "        logistic_test_pred = logistic_search.predict(X_test)\n",
        "        logistic_pred_proba = logistic_search.predict_proba(X_test)\n",
        "\n",
        "    if xgboost:\n",
        "        xgboost_search.fit(X_train, y_train)\n",
        "        xgboost_train_pred = xgboost_search.predict(X_train)\n",
        "        xgboost_test_pred = xgboost_search.predict(X_test)\n",
        "        xgboost_test_pred_proba = xgboost_search.predict_proba(X_test)\n",
        "\n",
        "    #When hyperparameter tuning, pass our best estimators into votingclassifier. Only run when all 3 models are being tuned.\n",
        "    if forest and logistic and xgboost:\n",
        "        voting_model = VotingClassifier(estimators=[('forest', forest_search.best_estimator_), #VotingClassifier is Soft Voting/Majority Rule classifier for unfitted estimators\n",
        "                                                    ('logistic', logistic_search.best_estimator_),\n",
        "                                                    ('xgboost', xgboost_search.best_estimator_),],\n",
        "                                        voting='soft') #soft voting per recommendation from sklearn documentation, when used on tuned classifiers.\n",
        "        voting_model.fit(X_train, y_train)\n",
        "\n",
        "else: #If we are not hyperparameter tuning, pass in our best params(from previous tuning runs).\n",
        "    forest_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
        "                            ('model', RandomForestClassifier(random_state=1337,\n",
        "                                                        max_depth=13,\n",
        "                                                        max_features=11,\n",
        "                                                        min_samples_leaf=2,\n",
        "                                                        n_estimators=450))])\n",
        "    logistic_pipeline = Pipeline([('encoder', ce.OneHotEncoder()),\n",
        "                                ('scaler', StandardScaler()),\n",
        "                                ('kbest', SelectKBest(k=19)),\n",
        "                                ('model', LogisticRegression(random_state=1337, C=0.01))])\n",
        "\n",
        "    xgboost_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
        "                                ('model', XGBClassifier(random_state=1337, n_estimators=175, min_child_weight=1,\n",
        "                                                min_child_leaf=2, max_depth=11, learning_rate=0.04,\n",
        "                                                gamma=0, subsample=0.8, colsample_bytree=0.3, scale_pos_weight=100))])\n",
        "\n",
        "\n",
        "    X_train, y_train = RandomOverSampler(sampling_strategy='not majority').fit_resample(X_train, y_train) #over sample all but the majority class\n",
        "\n",
        "    forest_pipeline.fit(X_train, y_train)\n",
        "    forest_train_pred = forest_pipeline.predict(X_train)\n",
        "    forest_test_pred = forest_pipeline.predict(X_test)\n",
        "    forest_test_pred_proba = forest_pipeline.predict_proba(X_test)\n",
        "\n",
        "    logistic_pipeline.fit(X_train, y_train)\n",
        "    logistic_train_pred = logistic_pipeline.predict(X_train)\n",
        "    logistic_test_pred = logistic_pipeline.predict(X_test)\n",
        "    logistic_test_pred_proba = logistic_pipeline.predict_proba(X_test)\n",
        "\n",
        "    xgboost_pipeline.fit(X_train, y_train)\n",
        "    xgboost_train_pred = xgboost_pipeline.predict(X_train)\n",
        "    xgboost_test_pred = xgboost_pipeline.predict(X_test)\n",
        "    xgboost_test_pred_proba = xgboost_pipeline.predict_proba(X_test)\n",
        "\n",
        "    voting_model = VotingClassifier(estimators=[('forest', forest_pipeline), #VotingClassifier is Soft Voting/Majority Rule classifier for unfitted estimators\n",
        "                                                ('logistic', logistic_pipeline),\n",
        "                                                ('xgboost', xgboost_pipeline),],\n",
        "                                    voting='soft') #soft voting per recommendation from sklearn documentation, when used on tuned classifiers.\n",
        "    voting_model.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Y9kRviyy7RRA",
        "colab_type": "code",
        "colab": {},
        "outputId": "0b501035-3a7e-4c34-ca24-7202abc6bf86"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score, plot_roc_curve\n",
        "if tune:\n",
        "    target_names = ['Average', 'Bad', 'Excellent']\n",
        "\n",
        "    if forest:\n",
        "        print(forest_search.best_params_, '\\n')\n",
        "        print(\"Best Random Forest CV score: \", forest_search.best_score_, '\\n')\n",
        "        print(\"Random forest ROC-AUC: \", roc_auc_score(y_test, forest_test_pred_proba, multi_class='ovr', labels=target_names), '\\n')\n",
        "        print(classification_report(y_test, forest_test_pred, target_names=target_names), '\\n')\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "    if logistic:\n",
        "        print(logistic_search.best_params_, '\\n')\n",
        "        print(\"Best logistic regression CV score: \", logistic_search.best_score_, '\\n')\n",
        "        print(\"Logistic regression ROC-AUC: \", roc_auc_score(y_test, logistic_test_pred_proba, multi_class='ovr', labels=target_names), '\\n')\n",
        "        print(classification_report(y_test, logistic_test_pred, target_names=target_names), '\\n')\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "    if xgboost:\n",
        "        print(xgboost_search.best_params_, '\\n')\n",
        "        print(\"Best xgboost CV score: \", xgboost_search.best_score_, '\\n')\n",
        "        print(\"Xgboost ROC-AUC: \", roc_auc_score(y_test, xgboost_test_pred_proba, multi_class='ovr', labels=target_names), '\\n')\n",
        "        print(classification_report(y_test, xgboost_test_pred, target_names=target_names), '\\n')\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "    print(\"Voting classifier, final accuracy score on test set: \", voting_model.score(X_test, y_test))\n",
        "\n",
        "    combined_model = voting_model.predict_proba(X_test)\n",
        "    print(\"Voting classifier, final ROC AUC on test set: \", roc_auc_score(y_test, combined_model, multi_class='ovr', labels=target_names))\n",
        "else:\n",
        "    target_names = ['Average', 'Bad', 'Excellent']\n",
        "    print(\"Random forest ROC-AUC: \", roc_auc_score(y_test, forest_test_pred_proba, multi_class='ovr', labels=target_names), '\\n')\n",
        "    print(classification_report(y_test, forest_test_pred, target_names=target_names))\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "    print(\"Logistic regression ROC-AUC: \", roc_auc_score(y_test, logistic_test_pred_proba, multi_class='ovr', labels=target_names), '\\n')\n",
        "    print(classification_report(y_test, logistic_test_pred, target_names=target_names))\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "    print(\"Xgboost ROC-AUC: \", roc_auc_score(y_test, xgboost_test_pred_proba, multi_class='ovr', labels=target_names), '\\n')\n",
        "    print(classification_report(y_test, xgboost_test_pred, target_names=target_names))\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "    print(\"Voting classifier, final accuracy score on test set: \", voting_model.score(X_test, y_test))\n",
        "\n",
        "    combined_model = voting_model.predict_proba(X_test)\n",
        "    print(\"Voting classifier, final ROC AUC on test set: \", roc_auc_score(y_test, combined_model, multi_class='ovr', labels=target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random forest ROC-AUC:  0.7153965634213413 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Average       0.60      0.57      0.59        47\n",
            "         Bad       0.27      0.38      0.32         8\n",
            "   Excellent       0.53      0.52      0.53        46\n",
            "\n",
            "    accuracy                           0.53       101\n",
            "   macro avg       0.47      0.49      0.48       101\n",
            "weighted avg       0.54      0.53      0.54       101\n",
            "\n",
            "\n",
            "\n",
            "Logistic regression ROC-AUC:  0.6404593466319466 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Average       0.62      0.45      0.52        47\n",
            "         Bad       0.21      0.38      0.27         8\n",
            "   Excellent       0.55      0.63      0.59        46\n",
            "\n",
            "    accuracy                           0.52       101\n",
            "   macro avg       0.46      0.48      0.46       101\n",
            "weighted avg       0.55      0.52      0.53       101\n",
            "\n",
            "\n",
            "\n",
            "Xgboost ROC-AUC:  0.6878720368248682 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Average       0.55      0.57      0.56        47\n",
            "         Bad       0.25      0.12      0.17         8\n",
            "   Excellent       0.48      0.50      0.49        46\n",
            "\n",
            "    accuracy                           0.50       101\n",
            "   macro avg       0.43      0.40      0.41       101\n",
            "weighted avg       0.49      0.50      0.50       101\n",
            "\n",
            "\n",
            "\n",
            "Voting classifier, final accuracy score on test set:  0.5643564356435643\n",
            "Voting classifier, final ROC AUC on test set:  0.7036546109907592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "INFSpr187RRD",
        "colab_type": "code",
        "colab": {},
        "outputId": "d17701d3-3261-4c8e-fb76-581dd4cbeefd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if tune:\n",
        "    model = forest_search.best_estimator_.named_steps.model\n",
        "    encoder = forest_search.best_estimator_.named_steps.encoder\n",
        "else:\n",
        "    model = forest_pipeline.named_steps.model\n",
        "    encoder = forest_pipeline.named_steps.encoder\n",
        "\n",
        "\n",
        "encoded_columns = encoder.transform(X_test).columns\n",
        "importances = pd.Series(model.feature_importances_, encoded_columns)\n",
        "plt.figure(figsize=(10,30))\n",
        "importances.sort_values().plot.barh(color='grey');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x2160 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nSEobzbf7RRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "#\n",
        "# import seaborn as sns\n",
        "# plt.figure(figsize=(16,9))\n",
        "# sns.barplot(\n",
        "#     x=train[train['Nr. reviews'] < 200]['Nr. reviews'],\n",
        "#     y=train['Score'],\n",
        "#     color='grey'\n",
        "# );"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ENDw4kPZ7RRJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "caa0719b-ebd0-40ba-ad96-ca18f8cb0f87"
      },
      "source": [
        "###While this is a good way to evaluate the estimator we are passing in, unless using a 3 way train/validate/test split, this should not be used for feature selection.\n",
        "###Instead, passing in an unfit estimator and specifying the amount of CV rounds will allow us to see more generalized permutation importance.\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "permuter = PermutationImportance(\n",
        "    forest_pipeline.named_steps.model, #pass in prefit estimator\n",
        "    scoring='neg_log_loss',\n",
        "    n_iter=100,\n",
        "    random_state=1337\n",
        ")\n",
        "\n",
        "permuter.fit(forest_pipeline.named_steps.encoder.transform(X_test), y_test) #only plotting random forest for now, though we use 3 models."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PermutationImportance(cv='prefit',\n",
              "                      estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                       ccp_alpha=0.0,\n",
              "                                                       class_weight=None,\n",
              "                                                       criterion='gini',\n",
              "                                                       max_depth=13,\n",
              "                                                       max_features=11,\n",
              "                                                       max_leaf_nodes=None,\n",
              "                                                       max_samples=None,\n",
              "                                                       min_impurity_decrease=0.0,\n",
              "                                                       min_impurity_split=None,\n",
              "                                                       min_samples_leaf=2,\n",
              "                                                       min_samples_split=2,\n",
              "                                                       min_weight_fraction_leaf=0.0,\n",
              "                                                       n_estimators=450,\n",
              "                                                       n_jobs=None,\n",
              "                                                       oob_score=False,\n",
              "                                                       random_state=1337,\n",
              "                                                       verbose=0,\n",
              "                                                       warm_start=False),\n",
              "                      n_iter=100, random_state=1337, refit=True,\n",
              "                      scoring='neg_log_loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 537
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "i8-wjTw_7RRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_names = X_test.columns.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xTHfIFod7RRO",
        "colab_type": "code",
        "colab": {},
        "outputId": "c2a2b9c1-6fba-4c3d-99ac-e802c6dbd376"
      },
      "source": [
        "eli5.show_weights(\n",
        "    permuter,\n",
        "    top=None,\n",
        "    feature_names=feature_names\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0274\n",
              "                \n",
              "                    &plusmn; 0.0440\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Hotel stars\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 82.23%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0231\n",
              "                \n",
              "                    &plusmn; 0.0303\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Nr. reviews\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 82.23%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0231\n",
              "                \n",
              "                    &plusmn; 0.0485\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Hotel name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 83.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0211\n",
              "                \n",
              "                    &plusmn; 0.0309\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Nr. hotel reviews\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 87.58%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0139\n",
              "                \n",
              "                    &plusmn; 0.0106\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                User country\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 88.07%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0131\n",
              "                \n",
              "                    &plusmn; 0.0183\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Helpful votes\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 89.38%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0111\n",
              "                \n",
              "                    &plusmn; 0.0173\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Nr. rooms\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 89.38%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0111\n",
              "                \n",
              "                    &plusmn; 0.0181\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Review weekday\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 92.23%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0071\n",
              "                \n",
              "                    &plusmn; 0.0137\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Review month\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0051\n",
              "                \n",
              "                    &plusmn; 0.0041\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Free internet\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.26%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0035\n",
              "                \n",
              "                    &plusmn; 0.0136\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Period of stay\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.07%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0027\n",
              "                \n",
              "                    &plusmn; 0.0084\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                User continent\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.12%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0017\n",
              "                \n",
              "                    &plusmn; 0.0039\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Tennis court\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0030\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Pool\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 97.93%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0011\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Gym\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 97.04%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0018\n",
              "                \n",
              "                    &plusmn; 0.0027\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Spa\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 95.98%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0028\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Casino\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 94.40%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0044\n",
              "                \n",
              "                    &plusmn; 0.0215\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                Traveler type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 539
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "31YPnxdx7RRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}