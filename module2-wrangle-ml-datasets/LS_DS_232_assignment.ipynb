{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "LS_DS_232_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mherbert93/DS-Unit-2-Applied-Modeling/blob/master/module2-wrangle-ml-datasets/LS_DS_232_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0AzFlBjSKsR",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 1*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Wrangle ML datasets\n",
        "\n",
        "- [x] Continue to clean and explore your data. \n",
        "- [x] For the evaluation metric you chose, what score would you get just by guessing?\n",
        "- [x] Can you make a fast, first model that beats guessing?\n",
        "\n",
        "**We recommend that you use your portfolio project dataset for all assignments this sprint.**\n",
        "\n",
        "**But if you aren't ready yet, or you want more practice, then use the New York City property sales dataset for today's assignment.** Follow the instructions below, to just keep a subset for the Tribeca neighborhood, and remove outliers or dirty data. [Here's a video walkthrough](https://youtu.be/pPWFw8UtBVg?t=584) you can refer to if you get stuck or want hints!\n",
        "\n",
        "- Data Source: [NYC OpenData: NYC Citywide Rolling Calendar Sales](https://data.cityofnewyork.us/dataset/NYC-Citywide-Rolling-Calendar-Sales/usep-8jbt)\n",
        "- Glossary: [NYC Department of Finance: Rolling Sales Data](https://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqzBTxmARmNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "a813513a-4f75-43d7-b2c7-dbda0f74b089"
      },
      "source": [
        "!pip install category-encoders"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category-encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 1.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (1.0.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (1.18.2)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category-encoders) (0.14.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category-encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category-encoders) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category-encoders) (1.12.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt3jD9iJRlZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00397/LasVegasTripAdvisorReviews-Dataset.csv\", sep=';')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RPcZpRqvRlZr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e52e3c8e-c062-4cdf-bd72-f6946b89406c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User country</th>\n",
              "      <th>Nr. reviews</th>\n",
              "      <th>Nr. hotel reviews</th>\n",
              "      <th>Helpful votes</th>\n",
              "      <th>Score</th>\n",
              "      <th>Period of stay</th>\n",
              "      <th>Traveler type</th>\n",
              "      <th>Pool</th>\n",
              "      <th>Gym</th>\n",
              "      <th>Tennis court</th>\n",
              "      <th>Spa</th>\n",
              "      <th>Casino</th>\n",
              "      <th>Free internet</th>\n",
              "      <th>Hotel name</th>\n",
              "      <th>Hotel stars</th>\n",
              "      <th>Nr. rooms</th>\n",
              "      <th>User continent</th>\n",
              "      <th>Member years</th>\n",
              "      <th>Review month</th>\n",
              "      <th>Review weekday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>USA</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>Dec-Feb</td>\n",
              "      <td>Friends</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>YES</td>\n",
              "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
              "      <td>3</td>\n",
              "      <td>3773</td>\n",
              "      <td>North America</td>\n",
              "      <td>9</td>\n",
              "      <td>January</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>USA</td>\n",
              "      <td>119</td>\n",
              "      <td>21</td>\n",
              "      <td>75</td>\n",
              "      <td>3</td>\n",
              "      <td>Dec-Feb</td>\n",
              "      <td>Business</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>YES</td>\n",
              "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
              "      <td>3</td>\n",
              "      <td>3773</td>\n",
              "      <td>North America</td>\n",
              "      <td>3</td>\n",
              "      <td>January</td>\n",
              "      <td>Friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>USA</td>\n",
              "      <td>36</td>\n",
              "      <td>9</td>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>Mar-May</td>\n",
              "      <td>Families</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>YES</td>\n",
              "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
              "      <td>3</td>\n",
              "      <td>3773</td>\n",
              "      <td>North America</td>\n",
              "      <td>2</td>\n",
              "      <td>February</td>\n",
              "      <td>Saturday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UK</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>Mar-May</td>\n",
              "      <td>Friends</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>YES</td>\n",
              "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
              "      <td>3</td>\n",
              "      <td>3773</td>\n",
              "      <td>Europe</td>\n",
              "      <td>6</td>\n",
              "      <td>February</td>\n",
              "      <td>Friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Canada</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>Mar-May</td>\n",
              "      <td>Solo</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>YES</td>\n",
              "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
              "      <td>3</td>\n",
              "      <td>3773</td>\n",
              "      <td>North America</td>\n",
              "      <td>7</td>\n",
              "      <td>March</td>\n",
              "      <td>Tuesday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  User country  Nr. reviews  ...  Review month  Review weekday\n",
              "0          USA           11  ...       January        Thursday\n",
              "1          USA          119  ...       January          Friday\n",
              "2          USA           36  ...      February        Saturday\n",
              "3           UK           14  ...      February          Friday\n",
              "4       Canada            5  ...         March         Tuesday\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UzsEu0hKRlZy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "42aaadd4-4278-4ae6-fcba-760dcc5e805d"
      },
      "source": [
        "df['Score'].value_counts(normalize=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    0.450397\n",
              "4    0.325397\n",
              "3    0.142857\n",
              "2    0.059524\n",
              "1    0.021825\n",
              "Name: Score, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dVXW53DBRlZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c16f11a-4a01-45e7-bbd4-d9e97a41fe81"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "majority_class = df['Score'].mode()[0]\n",
        "y_pred = [majority_class] * len(df['Score'])\n",
        "\n",
        "print(\"Baseline accuracy is: \", accuracy_score(df['Score'], y_pred))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy is:  0.4503968253968254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QpNg8kmuRlZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, train_size=0.80, test_size=0.20, stratify=df['Score'], random_state=1337)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "oXacDMb0RlZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "0f3e1c01-bb58-4711-c6b6-6157686e45fd"
      },
      "source": [
        "train['Score'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    181\n",
              "4    131\n",
              "3     58\n",
              "2     24\n",
              "1      9\n",
              "Name: Score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rA8_PNsrRlaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrangle(X):\n",
        "\n",
        "    X = X.copy()\n",
        "\n",
        "    def country_aggregation(row): #reduce number of country categories to 4. 'USA', 'Canada', 'UK', and all else 'other'.\n",
        "        if row['User country'] != \"USA\" and row['User country'] != 'Canada' and row['User country'] != 'UK':\n",
        "            return \"Other\"\n",
        "        else:\n",
        "            return row['User country']\n",
        "\n",
        "    def score_aggregation(row):\n",
        "        if row['Score'] == 5:\n",
        "            return \"Excellent\"\n",
        "        elif row['Score'] == 4 or row['Score'] == 3:\n",
        "            return \"Average\"\n",
        "        else:\n",
        "            return \"Bad\"\n",
        "\n",
        "    X['User country'] = X.apply(country_aggregation, axis=1)\n",
        "    X['Score'] = X.apply(score_aggregation, axis=1)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dIknKlMTRlaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = wrangle(train)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "e02kV8MURlaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a0146a0a-4170-4853-9d87-dcaf96b4c6be"
      },
      "source": [
        "majority_class = train['Score'].mode()[0]\n",
        "y_pred = [majority_class] * len(train['Score'])\n",
        "\n",
        "print(\"Train baseline accuracy is: \", accuracy_score(train['Score'], y_pred))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train baseline accuracy is:  0.46898263027295284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tNFiPz1ERlaL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "171a6ed5-d06a-4a15-8f1e-d588de5f883e"
      },
      "source": [
        "majority_class = test['Score'].mode()[0]\n",
        "y_pred = [majority_class] * len(test['Score'])\n",
        "\n",
        "print(\"Test baseline accuracy is: \", accuracy_score(test['Score'], y_pred))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test baseline accuracy is:  0.46534653465346537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WfHN7ZOPRlaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = 'Score'\n",
        "\n",
        "train_features = train.drop([target], axis=1)\n",
        "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "categorical_features = train_features.select_dtypes(exclude='number').nunique().index.tolist()\n",
        "\n",
        "\n",
        "features = numeric_features + categorical_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "BT58weD2RlaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = train[target]\n",
        "X_train = train[features]\n",
        "X_test = test[features]\n",
        "y_test = test[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VvisZZ9kRlaV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd045cbd-0669-404b-9a3e-4de6a2ac2c9d"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(403, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fSzxVUwURlaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "outputId": "3b7645a6-09f0-457e-b4c8-008309af5ca9"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import category_encoders as ce\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "#from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "tune = False\n",
        "forest = False\n",
        "logistic = False\n",
        "xgboost = False\n",
        "adaboost = False\n",
        "svc = False\n",
        "\n",
        "forest_distributions = {\n",
        "    'model__n_estimators': range(250, 500, 50),\n",
        "    'model__max_depth': range(3, 14),\n",
        "    'model__max_features': range(2, 14),\n",
        "    'model__min_samples_leaf': range(2, 4)\n",
        "}\n",
        "logistic_distributions = {\n",
        "    'kbest__k': range(1, 20),\n",
        "    'model__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "}\n",
        "\n",
        "xgboost_distributions = {\n",
        "    'model__n_estimators': [75, 100, 125, 150, 175],\n",
        "    'model__max_depth': [6, 7, 8, 9, 10, 11, 12, 13],\n",
        "    'model__learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.07, 0.10, 0.12, 0.14, 0.16],\n",
        "    'model__min_child_leaf':[1, 2, 3],\n",
        "    'model__min_child_weight': [1, 2, 3, 4],\n",
        "    'model__colsample_bytree':[0.2, 0.3, 0.4, 0.50, 0.60, 0.70],\n",
        "    'model__subsample':[0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    'model__gamma':[0],\n",
        "    'model__scale_pos_weight': [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70,\n",
        "                                75, 80, 85, 90, 95, 100]\n",
        " }\n",
        "\n",
        "adaboost_distributions = {\n",
        "    'model__n_estimators': range(20, 100, 5),\n",
        "    'model__learning_rate': [0.0001, 0.0002, 0.0003, 0.0004,\n",
        "                             0.0005, 0.0006, 0.0007, 0.0008,\n",
        "                             0.0009, 0.001, 0.002, 0.003, 0.004, 0.005]\n",
        "}\n",
        "\n",
        "svc_distributions = {\n",
        "    'kbest__k': range(1, 20),\n",
        "    'model__kernel': ['linear', 'poly', 'rbf'],\n",
        "    'model__C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
        "    'model__gamma': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005,\n",
        "                     0.0006, 0.0007, 0.0008, 0.0009, 0.001, 0.002, 0.003, 0.004, 0.005]\n",
        "}\n",
        "\n",
        "if tune:\n",
        "\n",
        "    forest_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
        "                           ('model', RandomForestClassifier(random_state=1337))])\n",
        "\n",
        "    logistic_pipeline = Pipeline([('encoder', ce.OneHotEncoder()),\n",
        "                                ('scaler', StandardScaler()),\n",
        "                                ('kbest', SelectKBest()),\n",
        "                                ('model', LogisticRegression(random_state=1337))])\n",
        "\n",
        "    xgboost_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
        "                           ('model', XGBClassifier(seed=1337))])\n",
        "\n",
        "    adaboost_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
        "                           ('model', AdaBoostClassifier(random_state=1337))])\n",
        "\n",
        "    svc_pipeline = Pipeline([('encoder', ce.OneHotEncoder()),\n",
        "                             ('scaler', StandardScaler()),\n",
        "                             ('kbest', SelectKBest()),\n",
        "                             ('model', SVC(random_state=1337, probability=True))])\n",
        "\n",
        "    forest_search = GridSearchCV(\n",
        "        forest_pipeline,\n",
        "        param_grid=forest_distributions,\n",
        "        cv=3,\n",
        "        scoring='neg_log_loss',\n",
        "        verbose=10,\n",
        "        n_jobs=15\n",
        "    )\n",
        "    logistic_search = GridSearchCV(\n",
        "        logistic_pipeline,\n",
        "        param_grid=logistic_distributions,\n",
        "        cv=3,\n",
        "        scoring='neg_log_loss',\n",
        "        verbose=10,\n",
        "        n_jobs=15\n",
        "    )\n",
        "    xgboost_search = RandomizedSearchCV(\n",
        "        estimator=xgboost_pipeline,\n",
        "        param_distributions=xgboost_distributions,\n",
        "        n_iter=10000,\n",
        "        cv=3,\n",
        "        scoring='neg_log_loss',\n",
        "        verbose=10,\n",
        "        random_state=1337,\n",
        "        n_jobs=15\n",
        "    )\n",
        "    adaboost_search = GridSearchCV(\n",
        "        adaboost_pipeline,\n",
        "        param_grid=adaboost_distributions,\n",
        "        cv=3,\n",
        "        scoring='neg_log_loss',\n",
        "        verbose=10,\n",
        "        n_jobs=15\n",
        "    )\n",
        "    svc_search = GridSearchCV(\n",
        "        svc_pipeline,\n",
        "        param_grid=svc_distributions,\n",
        "        cv=3,\n",
        "        scoring='neg_log_loss',\n",
        "        verbose=10,\n",
        "        n_jobs=15\n",
        "    )\n",
        "\n",
        "    if forest:\n",
        "        forest_search.fit(X_train, y_train)\n",
        "        forest_train_pred = forest_search.predict(X_train)\n",
        "        forest_test_pred = forest_search.predict(X_test)\n",
        "\n",
        "    if logistic:\n",
        "        logistic_search.fit(X_train, y_train)\n",
        "        logistic_train_pred = logistic_search.predict(X_train)\n",
        "        logistic_test_pred = logistic_search.predict(X_test)\n",
        "\n",
        "    if xgboost:\n",
        "        xgboost_search.fit(X_train, y_train)\n",
        "        xgboost_train_pred = xgboost_search.predict(X_train)\n",
        "        xgboost_test_pred = xgboost_search.predict(X_test)\n",
        "\n",
        "    if adaboost:\n",
        "        adaboost_search.fit(X_train, y_train)\n",
        "        adaboost_train_pred = adaboost_search.predict(X_train)\n",
        "        adaboost_test_pred = adaboost_search.predict(X_test)\n",
        "\n",
        "    if svc:\n",
        "        X_train_resampled, y_train_resampled = RandomOverSampler(sampling_strategy='minority').fit_resample(X_train, y_train)\n",
        "        svc_search.fit(X_train_resampled, y_train_resampled)\n",
        "        svc_train_pred = svc_search.predict(X_train)\n",
        "        svc_test_pred = svc_search.predict(X_test)\n",
        "\n",
        "else:\n",
        "    forest_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
        "                            ('model', RandomForestClassifier(random_state=1337,\n",
        "                                                        max_depth=3,\n",
        "                                                        max_features=13,\n",
        "                                                        min_samples_leaf=2,\n",
        "                                                        n_estimators=400))])\n",
        "    logistic_pipeline = Pipeline([('encoder', ce.OneHotEncoder()),\n",
        "                                ('scaler', StandardScaler()),\n",
        "                                ('kbest', SelectKBest(k=9)),\n",
        "                                ('model', LogisticRegression(random_state=1337, C=0.01))])\n",
        "\n",
        "    xgboost_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
        "                                ('model', XGBClassifier(random_state=1337, n_estimators=75, min_child_weight=3,\n",
        "                                                min_child_leaf=2, max_depth=8, learning_rate=0.05,\n",
        "                                                gamma=0, subsample=0.5, colsample_bytree=0.3, scale_pos_weight=100))])\n",
        "\n",
        "    adaboost_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
        "                           ('model', AdaBoostClassifier(random_state=1337, n_estimators=70,\n",
        "                                                        learning_rate=0.0008))])\n",
        "\n",
        "    svc_pipeline = Pipeline([('encoder', ce.OneHotEncoder()),\n",
        "                             ('scaler', StandardScaler()),\n",
        "                             ('kbest', SelectKBest(k=18)),\n",
        "                             ('model', SVC(random_state=1337, probability=True, C=0.8, gamma=0.005,\n",
        "                                           kernel='rbf'))])\n",
        "\n",
        "    X_train_resampled, y_train_resampled = RandomOverSampler(sampling_strategy='not majority').fit_resample(X_train, y_train)\n",
        "\n",
        "    forest_pipeline.fit(X_train_resampled, y_train_resampled)\n",
        "    forest_train_pred = forest_pipeline.predict(X_train)\n",
        "    forest_test_pred = forest_pipeline.predict(X_test)\n",
        "\n",
        "    logistic_pipeline.fit(X_train_resampled, y_train_resampled)\n",
        "    logistic_train_pred = logistic_pipeline.predict(X_train)\n",
        "    logistic_test_pred = logistic_pipeline.predict(X_test)\n",
        "\n",
        "    xgboost_pipeline.fit(X_train_resampled, y_train_resampled)\n",
        "    xgboost_train_pred = xgboost_pipeline.predict(X_train)\n",
        "    xgboost_test_pred = xgboost_pipeline.predict(X_test)\n",
        "\n",
        "    adaboost_pipeline.fit(X_train_resampled, y_train_resampled)\n",
        "    adaboost_train_pred = adaboost_pipeline.predict(X_train)\n",
        "    adaboost_test_pred = adaboost_pipeline.predict(X_test)\n",
        "\n",
        "    svc_pipeline.fit(X_train_resampled, y_train_resampled)\n",
        "    svc_train_pred = svc_pipeline.predict(X_train)\n",
        "    svc_test_pred = svc_pipeline.predict(X_test)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 5",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7f1701fa650d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mforest_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mforest_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0mforest_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/category_encoders/ordinal.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, override_return_df)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mhandle_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         )\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/category_encoders/ordinal.py\u001b[0m in \u001b[0;36mordinal_encoding\u001b[0;34m(X_in, mapping, cols, handle_unknown, handle_missing)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mswitch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswitch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'col'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswitch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mapping'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0Ao2h3XuRlab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "if tune:\n",
        "    target_names = ['Average', 'Bad', 'Excellent']\n",
        "\n",
        "    if forest:\n",
        "        print(forest_search.best_params_, '\\n')\n",
        "        print(\"Best Random Forest CV score: \", forest_search.best_score_, '\\n')\n",
        "        print(classification_report(y_test, forest_test_pred, target_names=target_names), '\\n')\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "    if logistic:\n",
        "        print(logistic_search.best_params_, '\\n')\n",
        "        print(\"Best logistic regression CV score: \", logistic_search.best_score_, '\\n')\n",
        "        print(classification_report(y_test, logistic_test_pred, target_names=target_names), '\\n')\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "    if xgboost:\n",
        "        print(xgboost_search.best_params_, '\\n')\n",
        "        print(\"Best xgboost CV score: \", xgboost_search.best_score_, '\\n')\n",
        "        print(classification_report(y_test, xgboost_test_pred, target_names=target_names), '\\n')\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "    if adaboost:\n",
        "        print(adaboost_search.best_params_, '\\n')\n",
        "        print(\"Best adaboost CV score: \", adaboost_search.best_score_, '\\n')\n",
        "        print(classification_report(y_test, adaboost_test_pred, target_names=target_names), '\\n')\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "    if svc:\n",
        "        print(svc_search.best_params_, '\\n')\n",
        "        print(\"Best SVC CV score: \", svc_search.best_score_, '\\n')\n",
        "        print(classification_report(y_test, svc_test_pred, target_names=target_names), '\\n')\n",
        "else:\n",
        "    target_names = ['Average', 'Bad', 'Excellent']\n",
        "    print(\"Random forest test accuracy score:\", accuracy_score(y_test, forest_test_pred), '\\n')\n",
        "    print(classification_report(y_test, forest_test_pred, target_names=target_names))\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "    print(\"Logistic regression test accuracy score:\", accuracy_score(y_test, logistic_test_pred), '\\n')\n",
        "    print(classification_report(y_test, logistic_test_pred, target_names=target_names))\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "    print(\"Xgboost test accuracy score:\", accuracy_score(y_test, xgboost_test_pred), '\\n')\n",
        "    print(classification_report(y_test, xgboost_test_pred, target_names=target_names))\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "    print(\"Adaboost test accuracy score:\", accuracy_score(y_test, adaboost_test_pred), '\\n')\n",
        "    print(classification_report(y_test, adaboost_test_pred, target_names=target_names))\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "    print(\"SVC test accuracy score:\", accuracy_score(y_test, svc_test_pred), '\\n')\n",
        "    print(classification_report(y_test, svc_test_pred, target_names=target_names))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "83VyZYVBRlaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pandas as pd\n",
        "#\n",
        "# # Filenames of your submissions you want to ensemble\n",
        "# files = ['martin-herbert_random_forest_final.csv', 'martin-herbert_xgboost_final.csv', 'martin-herbert_best_submission_gradiantboost.csv']\n",
        "#\n",
        "# target = 'status_group'\n",
        "# submissions = (pd.read_csv(file)[[target]] for file in files)\n",
        "# ensemble = pd.concat(submissions, axis='columns')\n",
        "# majority_vote = ensemble.mode(axis='columns')[0]\n",
        "#\n",
        "# sample_submission = pd.read_csv('sample_submission.csv')\n",
        "# submission = sample_submission.copy()\n",
        "# submission[target] = majority_vote\n",
        "# submission.to_csv('my-ultimate-ensemble-submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r60oJrioRlah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.linear_model import RidgeCV\n",
        "# from sklearn.svm import SVR\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# import category_encoders as ce\n",
        "# from sklearn.pipeline import Pipeline\n",
        "# from sklearn.feature_selection import SelectKBest\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "#\n",
        "# lr_distributions = {\n",
        "#      'model__n_estimators': range(100, 300, 50),\n",
        "#      'model__max_depth': range(1, 8),\n",
        "#      'model__max_features': range(2, 12),\n",
        "#      'model__min_samples_leaf': range(1, 3)\n",
        "# }\n",
        "#\n",
        "# alphas = [0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]\n",
        "#\n",
        "# lr_pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
        "#                             ('scaler', StandardScaler()),\n",
        "#                             ('kbest', SelectKBest()),\n",
        "#                             ('model', RandomForestRegressor(random_state=1337))])\n",
        "#\n",
        "# lr_search = GridSearchCV(\n",
        "#     lr_pipeline,\n",
        "#     param_grid=lr_distributions,\n",
        "#     cv=3,\n",
        "#     scoring='neg_mean_absolute_error',\n",
        "#     verbose=10,\n",
        "#     n_jobs=-1\n",
        "#     )\n",
        "#\n",
        "# lr_search.fit(X_train, y_train)\n",
        "# lr_train_pred = lr_search.predict(X_train)\n",
        "# lr_test_pred = lr_search.predict(X_test)\n",
        "\n",
        "# lr_pipeline.fit(X_train, y_train)\n",
        "# lr_train_pred = lr_pipeline.predict(X_train)\n",
        "# lr_test_pred = lr_pipeline.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "n1e9IvPZRlak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def wrangle(X):\n",
        "#     X = X.copy()\n",
        "#\n",
        "#     def score_aggregation(row):\n",
        "#         if int(round(row['Score'])) == 5:\n",
        "#             return \"Excellent\"\n",
        "#         elif int(round(row['Score'])) == 4 or int(round(row['Score'])) == 3:\n",
        "#             return \"Average\"\n",
        "#         else:\n",
        "#             return \"Bad\"\n",
        "#\n",
        "#     if isinstance(X, np.ndarray):\n",
        "#         lr_test_pred_binned = np.empty(shape=(len(lr_test_pred), 1), dtype=object)\n",
        "#\n",
        "#         for i in range(len(lr_test_pred)):\n",
        "#             if int(round(lr_test_pred[i])) == 5:\n",
        "#                 lr_test_pred_binned[i] = 'Excellent'\n",
        "#             elif int(round(lr_test_pred[i])) == 4 or int(round(lr_test_pred[i])) == 3:\n",
        "#                 lr_test_pred_binned[i] = 'Average'\n",
        "#             else:\n",
        "#                 lr_test_pred_binned[i] = 'Bad'\n",
        "#         return lr_test_pred_binned\n",
        "#     else:\n",
        "#         X['Score'] = X.apply(score_aggregation, axis=1)\n",
        "#         return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4Dd9UtUlRlam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.metrics import classification_report\n",
        "#\n",
        "# test = wrangle(test)\n",
        "#\n",
        "# y_test = test[target]\n",
        "# lr_test_pred = wrangle(lr_test_pred)\n",
        "#\n",
        "# target_names = ['Average', 'Bad', 'Excellent']\n",
        "# print(lr_search.best_params_, '\\n')\n",
        "# print(\"Linear regression test accuracy score:\", accuracy_score(y_test, lr_test_pred), '\\n')\n",
        "# print(classification_report(y_test, lr_test_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UrzMGhxbRlap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if tune:\n",
        "    model = forest_search.best_estimator_.named_steps.model\n",
        "    encoder = forest_search.best_estimator_.named_steps.encoder\n",
        "else:\n",
        "    model = forest_pipeline.named_steps.model\n",
        "    encoder = forest_pipeline.named_steps.encoder\n",
        "\n",
        "\n",
        "encoded_columns = encoder.transform(X_test).columns\n",
        "importances = pd.Series(model.feature_importances_, encoded_columns)\n",
        "plt.figure(figsize=(10,30))\n",
        "importances.sort_values().plot.barh(color='grey');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "BJaEvdyRRlas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(16,9))\n",
        "sns.barplot(\n",
        "    x=train[train['Nr. reviews'] < 200]['Nr. reviews'],\n",
        "    y=train['Score'],\n",
        "    color='grey'\n",
        ");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xUflCNbXRlav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}